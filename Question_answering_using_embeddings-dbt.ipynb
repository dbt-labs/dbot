{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e3839a6-9146-4f60-b74b-19abbc24278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6cba9ae",
   "metadata": {},
   "source": [
    "# 1. Grab docs and parse them into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f13b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitemap = 'https://docs.getdbt.com/sitemap.xml'\n",
    "sitemap_res = requests.get(sitemap)\n",
    "sitemap_tree = ET.fromstring(sitemap_res.content)\n",
    "\n",
    "urls = []\n",
    "for url in sitemap_tree.findall(\"{http://www.sitemaps.org/schemas/sitemap/0.9}url\"):\n",
    "    loc = url.find(\"{http://www.sitemaps.org/schemas/sitemap/0.9}loc\")\n",
    "    urls.append(loc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b2489937",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    current_heading = ''\n",
    "    current_content = ''\n",
    "    for tag in soup.find_all(['h1', 'h2', 'h3', 'h4', 'p']):\n",
    "        if tag.name.startswith('h'):\n",
    "            # If we encounter a new heading, add the previous content to the table\n",
    "            if current_heading and current_content:\n",
    "                row = {}\n",
    "                row['title'] = soup.title.string.strip() if soup.title else ''\n",
    "                row['heading'] = current_heading\n",
    "                row['content'] = current_content\n",
    "                row['tokens'] = len(current_content.split())\n",
    "                table.append(row)\n",
    "            # Update the current heading and reset the current content\n",
    "            current_heading = tag.text.strip()\n",
    "            current_content = ''\n",
    "        else:\n",
    "            # Add the text to the current content for this heading\n",
    "            current_content += tag.text.strip()\n",
    "\n",
    "    # Add the last row to the table\n",
    "    if current_heading and current_content:\n",
    "        row = {}\n",
    "        row['title'] = soup.title.string.strip() if soup.title else ''\n",
    "        row['heading'] = current_heading\n",
    "        row['content'] = current_content\n",
    "        row['tokens'] = len(current_content.split())\n",
    "        table.append(row)\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(table)\n",
    "df = df.set_index([\"title\", \"heading\"])\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a17b88b9-7ea2-491e-9727-12617c74a77d",
   "metadata": {},
   "source": [
    "We preprocess the document sections by creating an embedding vector for each section. An embedding is a vector of numbers that helps us understand how semantically similar or different the texts are. The closer two embeddings are to each other, the more similar are their contents. See the [documentation on OpenAI embeddings](https://beta.openai.com/docs/guides/embeddings) for more information.\n",
    "\n",
    "This indexing stage can be executed offline and only runs once to precompute the indexes for the dataset so that each piece of content can be retrieved later. Since this is a small example, we will store and search the embeddings locally. If you have a larger dataset, consider using a vector search engine like [Pinecone](https://www.pinecone.io/), [Weaviate](https://github.com/semi-technologies/weaviate) or [Qdrant](https://qdrant.tech) to power the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba475f30-ef7f-431c-b60d-d5970b62ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str=EMBEDDING_MODEL) -> list[float]:\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "    \n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_embedding(r.content) for idx, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "737266aa-cbe7-4691-87c1-fce8a31632f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(fname: str) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "    \n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9c723-f838-4c75-8ed8-286b2e491a60",
   "metadata": {},
   "source": [
    "Again, we have hosted the embeddings for you so you don't have to re-calculate them from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab50bfca-cb02-41c6-b338-4400abe1d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = compute_doc_embeddings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa32cf88-9edb-4dc6-b4cf-a16a8de7d304",
   "metadata": {
    "tags": []
   },
   "source": [
    "So we have split our document library into sections, and encoded them by creating embedding vectors that represent each chunk. Next we will use these embeddings to answer our users' questions.\n",
    "\n",
    "# 2) Find the most similar document embeddings to the question embedding\n",
    "\n",
    "At the time of question-answering, to answer the user's query we compute the query embedding of the question and use it to find the most similar document sections. Since this is a small example, we store and search the embeddings locally. If you have a larger dataset, consider using a vector search engine like [Pinecone](https://www.pinecone.io/), [Weaviate](https://github.com/semi-technologies/weaviate) or [Qdrant](https://qdrant.tech) to power the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dcd680e9-f194-4180-b14f-fc357498eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.\n",
    "    \n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "def order_document_sections_by_query_similarity(query: str, contexts: dict[(str, str), np.array]) -> list[(float, (str, str))]:\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0efa0f6-4469-457a-89a4-a2f5736a01e0",
   "metadata": {},
   "source": [
    "# 3) Add the most relevant document sections to the query prompt\n",
    "\n",
    "Once we've calculated the most relevant pieces of context, we construct a prompt by simply prepending them to the supplied query. It is helpful to use a query separator to help the model distinguish between separate pieces of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b763ace2-1946-48e0-8ff1-91ba335d47a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context separator contains 3 tokens'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SECTION_LEN = 500\n",
    "SEPARATOR = \"\\n* \"\n",
    "ENCODING = \"gpt2\"  # encoding for text-davinci-003\n",
    "\n",
    "encoding = tiktoken.get_encoding(ENCODING)\n",
    "separator_len = len(encoding.encode(SEPARATOR))\n",
    "\n",
    "f\"Context separator contains {separator_len} tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0c5c0509-eeb9-4552-a5d4-6ace04ef73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant \n",
    "    \"\"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    \n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "     \n",
    "    for _, section_index in most_relevant_document_sections:\n",
    "        # Add contexts until we run out of space.\n",
    "        document_section = df.loc[section_index]\n",
    "        document_section = document_section.iloc[0]\n",
    "\n",
    "        # We've added `first` here because we seem to still be dealing with non-unique multi-indices\n",
    "        chosen_sections_len += document_section.tokens + separator_len\n",
    "        \n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "            \n",
    "        chosen_sections.append(SEPARATOR + document_section.content.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "            \n",
    "    # Useful diagnostic information\n",
    "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
    "    print(\"\\n\".join(chosen_sections_indexes))\n",
    "    \n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\\n\\nContext:\\n\"\"\"\n",
    "    \n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "48c5c1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 12 document sections:\n",
      "('Getting help | dbt Developer Hub', 'dbt Training\\u200b')\n",
      "('Overview | dbt Developer Hub', 'How do I get started?')\n",
      "('Overview | dbt Developer Hub', 'What is dbt?')\n",
      "('debug | dbt Developer Hub', 'Usage\\u200b')\n",
      "('What is dbt? | dbt Developer Hub', 'About dbt\\u200b')\n",
      "('dbt Developer Hub', 'Docs')\n",
      "('Teradata setup | dbt Developer Hub', 'Commands\\u200b')\n",
      "('Updating our permissioning guidelines: grants as configs in dbt Core v1.2 | dbt Developer Blog', 'The solution then\\u200b')\n",
      "('dbt Developer Hub', 'Supported data platforms')\n",
      "('What is dbt? | dbt Developer Hub', 'dbt Core\\u200b')\n",
      "('dbt Developer Blog', 'dbt Developer Blog')\n",
      "('dbt Developer Hub', 'What is dbt?')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/p4_th7xd6z91xpbf0hgtbk3w0000gp/T/ipykernel_36968/2959345404.py:13: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  document_section = df.loc[section_index]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don\\'t know.\"\\n\\nContext:\\n\\n* If you want to receive dbt training, check out our dbt Learn program.\\n* dbt is open source and completely free to download and use. See our Getting Started guide for more.\\n* dbt is a productivity tool that helps analysts get more done and produce higher quality results.Analysts commonly spend 50-80% of their time modeling raw dataâ€”cleaning, reshaping, and applying fundamental business logic to it. dbt empowers analysts to do this work better and faster.dbt\\'s primary interface is its CLI. Using dbt is a combination of editing code in a text editor and running that code using dbt from the command line using dbt [command] [options].\\n* When dbt hits the debug() line, you\\'ll see something like:\\n* dbt is a transformation workflow that helps you get more work done while producing higher quality results. You can use dbt to modularize and centralize your analytics code, while also providing your data team with guardrails typically found in software engineering workflows. Collaborate on data models, version them, and test and document your queries before safely deploying them to production, with monitoring and visibility.dbt compiles and runs your analytics code against your data platform, enabling you and your team to collaborate on a single source of truth for metrics, insights, and business definitions. This single source of truth, combined with the ability to define tests for your data, reduces errors when logic changes, and alerts you when issues arise.Read more about why we want to enable analysts to work more like software engineers in The dbt Viewpoint.\\n* Discover everything dbt has to offer from the basics to advanced concepts.\\n* All dbt commands are supported.\\n* Prior to dbt Core v1.2, we proposed three possible approaches (each coming with caveats and trade-offs):These options were the state of the art... until today!\\n* dbt connects to most major databases, data warehouses, data lakes, or query engines.\\n* dbt Core is an open-source tool that enables data teams to transform data using analytics engineering best practices. You can install and use dbt Core on the command line. Learn more with the quickstart for dbt Core.\\n* Technical tutorials from the dbt Community.\\n* dbt enables data practitioners to adopt software engineering best practices and deploy modular, reliable analytics code.\\n\\n Q: What is dbt?\\n A:'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_prompt('What is dbt?', document_embeddings, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b022fd4-0a3c-4ae1-bed1-4c80e4f0fb56",
   "metadata": {
    "tags": []
   },
   "source": [
    "We have now obtained the document sections that are most relevant to the question. As a final step, let's put it all together to get an answer to the question.\n",
    "\n",
    "# 4) Answer the user's question based on the context.\n",
    "\n",
    "Now that we've retrieved the relevant context and constructed our prompt, we can finally use the Completions API to answer the user's query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b0edfec7-9243-4573-92e0-253d31c771ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_API_PARAMS = {\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 300,\n",
    "    \"model\": COMPLETIONS_MODEL,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9c1c9a69-848e-4099-a90d-c8da36c153d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_context(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    document_embeddings: dict[(str, str), np.array],\n",
    "    show_prompt: bool = False\n",
    ") -> str:\n",
    "    prompt = construct_prompt(\n",
    "        query,\n",
    "        document_embeddings,\n",
    "        df\n",
    "    )\n",
    "    \n",
    "    if show_prompt:\n",
    "        print(prompt)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "                prompt=prompt,\n",
    "                **COMPLETIONS_API_PARAMS\n",
    "            )\n",
    "\n",
    "    return response[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c233e449-bf33-4c9e-b095-6a4dd278c8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/p4_th7xd6z91xpbf0hgtbk3w0000gp/T/ipykernel_36968/2959345404.py:13: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  document_section = df.loc[section_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 6 document sections:\n",
      "('Incremental models | dbt Developer Hub', 'Overview\\u200b')\n",
      "('Materializations | dbt Developer Hub', 'Incremental\\u200b')\n",
      "('Incremental models in-depth | dbt Developer Hub', 'Configuring incremental models\\u200b')\n",
      "('Incremental models in-depth | dbt Developer Hub', 'Incremental models in-depth')\n",
      "('Incremental models | dbt Developer Hub', 'Configuring incremental strategy\\u200b')\n",
      "('Incremental models in-depth | dbt Developer Hub', 'Writing incremental logic\\u200b')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You can write an incremental model in dbt using the {{ this }} keyword. An example code block would look like this: \\n\\n`SELECT * FROM {{ source('my_table') }} WHERE {{ this.created_at > ref('last_run') }}`\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I write an incremental model in dbt? Can you show me example code?\"\n",
    "answer_query_with_context(question, df, document_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('openai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
